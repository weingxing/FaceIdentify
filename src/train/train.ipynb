{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "colab": {
   "name": "train",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LmATA4AAJX6",
    "colab_type": "text"
   },
   "source": [
    "## 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rx8z0VTw5PBz",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "outputId": "f1c060d3-106d-488b-ac1a-4c749867aee6"
   },
   "source": [
    "# 挂载Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8hGT7A8b5Pq2",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "outputId": "e117ea63-2f4f-4704-88eb-83e393734e8f"
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Tue Apr 14 04:18:41 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yYq9egi75SGq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "outputId": "373ff62d-f775-4f6b-b1fd-e794109dcc4a"
   },
   "source": [
    "# 查看CUDA信息\n",
    "!nvcc --version"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pIdO1XfO5T2r",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "577f9abf-a978-450e-dcf9-5e772ffd18f3"
   },
   "source": [
    "# 降级CUDA\n",
    "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
    "!apt-get update\n",
    "!apt-get install cuda=9.0.176-1"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--2020-04-14 04:18:48--  https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
      "Resolving developer.nvidia.com (developer.nvidia.com)... 152.199.0.24\n",
      "Connecting to developer.nvidia.com (developer.nvidia.com)|152.199.0.24|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?s1_Ozr4DjyHHmRiU84OLgsrxMifPS43WHwxSRNRY6NnQ-C9_eILIQTrj0fSDiWkQaPJElA7GmDX-ezDySnrg0-VLg-juCyEHzGFS-A4n46WEtP2j2cK-XpV8EpyeqahcdHmiQjUTdkyVXEnC5oUgLYz-9QnB3ME79T6Tcqxr-iOu65sAU3EE6Fubzulv7nyO6s4cgU6gFhZTrzzmnpOa [following]\n",
      "--2020-04-14 04:18:48--  https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?s1_Ozr4DjyHHmRiU84OLgsrxMifPS43WHwxSRNRY6NnQ-C9_eILIQTrj0fSDiWkQaPJElA7GmDX-ezDySnrg0-VLg-juCyEHzGFS-A4n46WEtP2j2cK-XpV8EpyeqahcdHmiQjUTdkyVXEnC5oUgLYz-9QnB3ME79T6Tcqxr-iOu65sAU3EE6Fubzulv7nyO6s4cgU6gFhZTrzzmnpOa\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1212738714 (1.1G) [application/x-deb]\n",
      "Saving to: ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’\n",
      "\n",
      "cuda-repo-ubuntu160 100%[===================>]   1.13G   196MB/s    in 6.0s    \n",
      "\n",
      "2020-04-14 04:18:54 (193 MB/s) - ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’ saved [1212738714/1212738714]\n",
      "\n",
      "Selecting previously unselected package cuda-repo-ubuntu1604-9-0-local.\n",
      "(Reading database ... 144568 files and directories currently installed.)\n",
      "Preparing to unpack cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb ...\n",
      "Unpacking cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
      "Setting up cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
      "OK\n",
      "Get:1 file:/var/cuda-repo-9-0-local  InRelease\n",
      "Ign:1 file:/var/cuda-repo-9-0-local  InRelease\n",
      "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
      "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
      "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
      "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
      "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:9 file:/var/cuda-repo-9-0-local  Packages [15.4 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [88.1 kB]\n",
      "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [839 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [12.6 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,183 kB]\n",
      "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,810 kB]\n",
      "Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [889 kB]\n",
      "Get:25 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [8,213 B]\n",
      "Get:26 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [44.6 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,371 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [59.0 kB]\n",
      "Get:29 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [874 kB]\n",
      "Fetched 7,509 kB in 4s (1,946 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
      "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
      "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
      "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
      "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
      "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
      "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
      "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
      "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
      "The following NEW packages will be installed:\n",
      "  cuda cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
      "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
      "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
      "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
      "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
      "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
      "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
      "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
      "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
      "0 upgraded, 34 newly installed, 0 to remove and 56 not upgraded.\n",
      "Need to get 0 B/1,097 MB of archives.\n",
      "After this operation, 2,315 MB of additional disk space will be used.\n",
      "Get:1 file:/var/cuda-repo-9-0-local  cuda-license-9-0 9.0.176-1 [22.0 kB]\n",
      "Get:2 file:/var/cuda-repo-9-0-local  cuda-misc-headers-9-0 9.0.176-1 [684 kB]\n",
      "Get:3 file:/var/cuda-repo-9-0-local  cuda-core-9-0 9.0.176-1 [16.9 MB]\n",
      "Get:4 file:/var/cuda-repo-9-0-local  cuda-cudart-9-0 9.0.176-1 [106 kB]\n",
      "Get:5 file:/var/cuda-repo-9-0-local  cuda-driver-dev-9-0 9.0.176-1 [10.9 kB]\n",
      "Get:6 file:/var/cuda-repo-9-0-local  cuda-cudart-dev-9-0 9.0.176-1 [767 kB]\n",
      "Get:7 file:/var/cuda-repo-9-0-local  cuda-command-line-tools-9-0 9.0.176-1 [25.4 MB]\n",
      "Get:8 file:/var/cuda-repo-9-0-local  cuda-nvrtc-9-0 9.0.176-1 [6,348 kB]\n",
      "Get:9 file:/var/cuda-repo-9-0-local  cuda-nvrtc-dev-9-0 9.0.176-1 [9,334 B]\n",
      "Get:10 file:/var/cuda-repo-9-0-local  cuda-cusolver-9-0 9.0.176-1 [26.2 MB]\n",
      "Get:11 file:/var/cuda-repo-9-0-local  cuda-cusolver-dev-9-0 9.0.176-1 [5,317 kB]\n",
      "Get:12 file:/var/cuda-repo-9-0-local  cuda-cublas-9-0 9.0.176-1 [25.0 MB]\n",
      "Get:13 file:/var/cuda-repo-9-0-local  cuda-cublas-dev-9-0 9.0.176-1 [49.4 MB]\n",
      "Get:14 file:/var/cuda-repo-9-0-local  cuda-cufft-9-0 9.0.176-1 [84.1 MB]\n",
      "Get:15 file:/var/cuda-repo-9-0-local  cuda-cufft-dev-9-0 9.0.176-1 [73.7 MB]\n",
      "Get:16 file:/var/cuda-repo-9-0-local  cuda-curand-9-0 9.0.176-1 [38.8 MB]\n",
      "Get:17 file:/var/cuda-repo-9-0-local  cuda-curand-dev-9-0 9.0.176-1 [57.9 MB]\n",
      "Get:18 file:/var/cuda-repo-9-0-local  cuda-cusparse-9-0 9.0.176-1 [25.2 MB]\n",
      "Get:19 file:/var/cuda-repo-9-0-local  cuda-cusparse-dev-9-0 9.0.176-1 [25.3 MB]\n",
      "Get:20 file:/var/cuda-repo-9-0-local  cuda-npp-9-0 9.0.176-1 [46.6 MB]\n",
      "Get:21 file:/var/cuda-repo-9-0-local  cuda-npp-dev-9-0 9.0.176-1 [46.6 MB]\n",
      "Get:22 file:/var/cuda-repo-9-0-local  cuda-nvgraph-9-0 9.0.176-1 [6,081 kB]\n",
      "Get:23 file:/var/cuda-repo-9-0-local  cuda-nvgraph-dev-9-0 9.0.176-1 [5,658 kB]\n",
      "Get:24 file:/var/cuda-repo-9-0-local  cuda-samples-9-0 9.0.176-1 [75.9 MB]\n",
      "Get:25 file:/var/cuda-repo-9-0-local  cuda-documentation-9-0 9.0.176-1 [53.1 MB]\n",
      "Get:26 file:/var/cuda-repo-9-0-local  cuda-libraries-dev-9-0 9.0.176-1 [2,596 B]\n",
      "Get:27 file:/var/cuda-repo-9-0-local  cuda-nvml-dev-9-0 9.0.176-1 [47.6 kB]\n",
      "Get:28 file:/var/cuda-repo-9-0-local  cuda-visual-tools-9-0 9.0.176-1 [398 MB]\n",
      "Get:29 file:/var/cuda-repo-9-0-local  cuda-toolkit-9-0 9.0.176-1 [2,836 B]\n",
      "Get:30 file:/var/cuda-repo-9-0-local  cuda-libraries-9-0 9.0.176-1 [2,566 B]\n",
      "Get:31 file:/var/cuda-repo-9-0-local  cuda-runtime-9-0 9.0.176-1 [2,526 B]\n",
      "Get:32 file:/var/cuda-repo-9-0-local  cuda-demo-suite-9-0 9.0.176-1 [3,880 kB]\n",
      "Get:33 file:/var/cuda-repo-9-0-local  cuda-9-0 9.0.176-1 [2,552 B]\n",
      "Get:34 file:/var/cuda-repo-9-0-local  cuda 9.0.176-1 [2,504 B]\n",
      "Extracting templates from packages: 100%\n",
      "Selecting previously unselected package cuda-license-9-0.\n",
      "(Reading database ... 144627 files and directories currently installed.)\n",
      "Preparing to unpack .../00-cuda-license-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-license-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-misc-headers-9-0.\n",
      "Preparing to unpack .../01-cuda-misc-headers-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-misc-headers-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-core-9-0.\n",
      "Preparing to unpack .../02-cuda-core-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-core-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cudart-9-0.\n",
      "Preparing to unpack .../03-cuda-cudart-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-driver-dev-9-0.\n",
      "Preparing to unpack .../04-cuda-driver-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-driver-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cudart-dev-9-0.\n",
      "Preparing to unpack .../05-cuda-cudart-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-command-line-tools-9-0.\n",
      "Preparing to unpack .../06-cuda-command-line-tools-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-9-0.\n",
      "Preparing to unpack .../07-cuda-nvrtc-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-dev-9-0.\n",
      "Preparing to unpack .../08-cuda-nvrtc-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cusolver-9-0.\n",
      "Preparing to unpack .../09-cuda-cusolver-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cusolver-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cusolver-dev-9-0.\n",
      "Preparing to unpack .../10-cuda-cusolver-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cublas-9-0.\n",
      "Preparing to unpack .../11-cuda-cublas-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cublas-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cublas-dev-9-0.\n",
      "Preparing to unpack .../12-cuda-cublas-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cufft-9-0.\n",
      "Preparing to unpack .../13-cuda-cufft-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cufft-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cufft-dev-9-0.\n",
      "Preparing to unpack .../14-cuda-cufft-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-curand-9-0.\n",
      "Preparing to unpack .../15-cuda-curand-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-curand-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-curand-dev-9-0.\n",
      "Preparing to unpack .../16-cuda-curand-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-curand-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cusparse-9-0.\n",
      "Preparing to unpack .../17-cuda-cusparse-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cusparse-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-cusparse-dev-9-0.\n",
      "Preparing to unpack .../18-cuda-cusparse-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-npp-9-0.\n",
      "Preparing to unpack .../19-cuda-npp-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-npp-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-npp-dev-9-0.\n",
      "Preparing to unpack .../20-cuda-npp-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-npp-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-nvgraph-9-0.\n",
      "Preparing to unpack .../21-cuda-nvgraph-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-nvgraph-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-nvgraph-dev-9-0.\n",
      "Preparing to unpack .../22-cuda-nvgraph-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-samples-9-0.\n",
      "Preparing to unpack .../23-cuda-samples-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-samples-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-documentation-9-0.\n",
      "Preparing to unpack .../24-cuda-documentation-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-documentation-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-libraries-dev-9-0.\n",
      "Preparing to unpack .../25-cuda-libraries-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-nvml-dev-9-0.\n",
      "Preparing to unpack .../26-cuda-nvml-dev-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-visual-tools-9-0.\n",
      "Preparing to unpack .../27-cuda-visual-tools-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-visual-tools-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-toolkit-9-0.\n",
      "Preparing to unpack .../28-cuda-toolkit-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-toolkit-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-libraries-9-0.\n",
      "Preparing to unpack .../29-cuda-libraries-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-runtime-9-0.\n",
      "Preparing to unpack .../30-cuda-runtime-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-runtime-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-demo-suite-9-0.\n",
      "Preparing to unpack .../31-cuda-demo-suite-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-demo-suite-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda-9-0.\n",
      "Preparing to unpack .../32-cuda-9-0_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda-9-0 (9.0.176-1) ...\n",
      "Selecting previously unselected package cuda.\n",
      "Preparing to unpack .../33-cuda_9.0.176-1_amd64.deb ...\n",
      "Unpacking cuda (9.0.176-1) ...\n",
      "Setting up cuda-license-9-0 (9.0.176-1) ...\n",
      "*** LICENSE AGREEMENT ***\n",
      "By using this software you agree to fully comply with the terms and \n",
      "conditions of the EULA (End User License Agreement). The EULA is located\n",
      "at /usr/local/cuda-9.0/doc/EULA.txt. The EULA can also be found at\n",
      "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
      "terms and conditions of the EULA, do not use the software.\n",
      "\n",
      "Setting up cuda-cusparse-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cudart-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-nvrtc-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cufft-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cusolver-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-npp-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-misc-headers-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cublas-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-driver-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-curand-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-nvgraph-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-core-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-libraries-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-runtime-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-npp-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-curand-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-demo-suite-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-visual-tools-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-samples-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-documentation-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-toolkit-9-0 (9.0.176-1) ...\n",
      "Setting up cuda-9-0 (9.0.176-1) ...\n",
      "Setting up cuda (9.0.176-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iAARAp0_5WA3",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "outputId": "26a188dc-0704-463b-f10e-4d1c91579d1a"
   },
   "source": [
    "# 查看是否降级成功\n",
    "!nvcc --version"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:03_CDT_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Oev8-WP5Xvg",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "outputId": "0906331d-fe89-4bc7-d049-027fa112b29a"
   },
   "source": [
    "!pip uninstall tensorflow-gpu -y\n",
    "!pip uninstall tensorflow -y\n",
    "!pip uninstall protobuf -y\n",
    "# 降级tensorflow，降级后重启内核\n",
    "!pip install tensorflow-gpu==1.12.0"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
      "Uninstalling tensorflow-2.2.0rc2:\n",
      "  Successfully uninstalled tensorflow-2.2.0rc2\n",
      "Uninstalling protobuf-3.10.0:\n",
      "  Successfully uninstalled protobuf-3.10.0\n",
      "Collecting tensorflow-gpu==1.12.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/7e/bec4d62e9dc95e828922c6cec38acd9461af8abe749f7c9def25ec4b2fdb/tensorflow_gpu-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (281.7MB)\n",
      "\u001b[K     |████████████████████████████████| 281.7MB 59kB/s \n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.18.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.12.0)\n",
      "Collecting tensorboard<1.13.0,>=1.12.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 48.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.28.1)\n",
      "Collecting protobuf>=3.6.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/02/5432412c162989260fab61fa65e0a490c1872739eb91a659896e4d554b26/protobuf-3.11.3-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 51.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0) (3.2.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.12.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0) (46.1.3)\n",
      "Installing collected packages: protobuf, tensorboard, tensorflow-gpu\n",
      "  Found existing installation: tensorboard 2.2.0\n",
      "    Uninstalling tensorboard-2.2.0:\n",
      "      Successfully uninstalled tensorboard-2.2.0\n",
      "Successfully installed protobuf-3.11.3 tensorboard-1.12.2 tensorflow-gpu-1.12.0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2f4F-vzM5cLS",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "outputId": "1df44a7b-9210-4cb0-9cbd-39e3398bc687"
   },
   "source": [
    "# 测试是否降级成功并查看tensorflow版本\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.test.is_gpu_available()"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3Q7Qst305eEY",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "outputId": "e034be3a-d3a3-488c-dd9c-55b6a1359ddb"
   },
   "source": [
    "# tensorboard\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--2020-04-14 04:25:22--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 34.202.14.95, 34.197.28.250, 34.192.215.160, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|34.202.14.95|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13773305 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.13M  18.8MB/s    in 0.7s    \n",
      "\n",
      "2020-04-14 04:25:23 (18.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bE71RlKi5gAR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "60ff7da0-332e-4516-db53-741e7ba9e864"
   },
   "source": [
    "LOG_DIR = './gdrive/My Drive/logs/facenet/'\n",
    "get_ipython().system_raw(\n",
    "'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    ".format(LOG_DIR)\n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "https://80d2928c.ngrok.io\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PVJOOaqh4Rse",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.training import training\n",
    "from tensorflow.python.ops import data_flow_ops\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "\n",
    "from six.moves import xrange\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "import sys\n",
    "import importlib\n",
    "import itertools"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeArvzi04Rsk",
    "colab_type": "text"
   },
   "source": [
    "## 训练用函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y5a_Rz9d4Rsl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Triplet Loss\n",
    "def triplet(anchor, positive, negative, alpha):\n",
    "    \"\"\"\n",
    "    Calculate the triplet loss according to the FaceNet paper\n",
    "    Args:\n",
    "      anchor: the embeddings for the anchor images.\n",
    "      positive: the embeddings for the positive images.\n",
    "      negative: the embeddings for the negative images.\n",
    "    Returns:\n",
    "      the triplet loss according to the FaceNet paper as a float tensor.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('triplet_loss'):\n",
    "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
    "\n",
    "        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def read_images_from_disk(input_queue):\n",
    "    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n",
    "    Args:\n",
    "      filename_and_label_tensor: A scalar string tensor.\n",
    "    Returns:\n",
    "      Two tensors: the decoded image, and the string label.\n",
    "    \"\"\"\n",
    "    label = input_queue[1]\n",
    "    file_contents = tf.read_file(input_queue[0])\n",
    "    example = tf.image.decode_image(file_contents, channels=3)\n",
    "    return example, label\n",
    "\n",
    "\n",
    "def random_rotate_image(image):\n",
    "    angle = np.random.uniform(low=-10.0, high=10.0)\n",
    "    return misc.imrotate(image, angle, 'bicubic')\n",
    "\n",
    "def _add_loss_summaries(total_loss):\n",
    "    \"\"\"Add summaries for losses.\n",
    "  \n",
    "    Generates moving average for all losses and associated summaries for\n",
    "    visualizing the performance of the network.\n",
    "  \n",
    "    Args:\n",
    "      total_loss: Total loss from loss().\n",
    "    Returns:\n",
    "      loss_averages_op: op for generating moving averages of losses.\n",
    "    \"\"\"\n",
    "    # Compute the moving average of all individual losses and the total loss.\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "    losses = tf.get_collection('losses')\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "    # Attach a scalar summmary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "        # as the original loss name.\n",
    "        tf.summary.scalar(l.op.name + ' (raw)', l)\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
    "\n",
    "    return loss_averages_op"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-AUgfzKa4Rs0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0 / np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1 / std_adj)\n",
    "    return y\n",
    "\n",
    "def crop(image, random_crop, image_size):\n",
    "    if image.shape[1] > image_size:\n",
    "        sz1 = int(image.shape[1] // 2)\n",
    "        sz2 = int(image_size // 2)\n",
    "        if random_crop:\n",
    "            diff = sz1 - sz2\n",
    "            (h, v) = (np.random.randint(-diff, diff + 1), np.random.randint(-diff, diff + 1))\n",
    "        else:\n",
    "            (h, v) = (0, 0)\n",
    "        image = image[(sz1 - sz2 + v):(sz1 + sz2 + v), (sz1 - sz2 + h):(sz1 + sz2 + h), :]\n",
    "    return image\n",
    "\n",
    "def flip(image, random_flip):\n",
    "    if random_flip and np.random.choice([True, False]):\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "def to_rgb(img):\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
    "    return ret\n",
    "\n",
    "# 得到具体图片的路径\n",
    "def get_image_paths(facedir):\n",
    "    image_paths = []  # 有几张图片就有几个元素\n",
    "    if os.path.isdir(facedir):\n",
    "        # 如果这个姓名下有图像，则读取图像列表\n",
    "        images = os.listdir(facedir)\n",
    "        image_paths = [os.path.join(facedir, img) for img in images]\n",
    "    return image_paths\n",
    "\n",
    "class ImageClass():\n",
    "    \"Stores the paths to images for a given class\"\n",
    "\n",
    "    def __init__(self, name, image_paths):\n",
    "        self.name = name\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "def get_dataset(path, has_class_directories=True):\n",
    "    dataset = []\n",
    "    # 简单理解就是规范化linux和windows下的路径名\n",
    "    path_exp = os.path.expanduser(path)\n",
    "    classes = [path for path in os.listdir(path_exp) \\\n",
    "               if os.path.isdir(os.path.join(path_exp, path))]\n",
    "    classes.sort()\n",
    "    # 把姓名都放在列表class这个列表里\n",
    "    nrof_classes = len(classes)\n",
    "    for i in range(nrof_classes):\n",
    "        class_name = classes[i]\n",
    "        facedir = os.path.join(path_exp, class_name)\n",
    "        image_paths = get_image_paths(facedir)\n",
    "        dataset.append(ImageClass(class_name, image_paths))\n",
    "\n",
    "    return dataset"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5XsEp5i-4RtB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def facenet_get_learning_rate_from_file(filename, epoch):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split('#', 1)[0]\n",
    "            if line:\n",
    "                par = line.strip().split(':')\n",
    "                e = int(par[0])\n",
    "                lr = float(par[1])\n",
    "                if e <= epoch:\n",
    "                    learning_rate = lr\n",
    "                else:\n",
    "                    return learning_rate\n",
    "\n",
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files) == 0:\n",
    "        raise ValueError('没有meta文件：(%s)' % model_dir)\n",
    "    elif len(meta_files) > 1:\n",
    "        raise ValueError('发现多个meta文件：(%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        return meta_file, ckpt_file\n",
    "\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups()) >= 2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file\n",
    "\n",
    "def load_model(model):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    if os.path.isfile(model_exp):\n",
    "        print('模型名称: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "    else:\n",
    "        print('模型目录: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "\n",
    "        print('metagraph文件: %s' % meta_file)\n",
    "        print('checkpoint文件: %s' % ckpt_file)\n",
    "\n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "\n",
    "# 记录参数日志\n",
    "def write_arguments_to_file(args, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for key in args.keys():\n",
    "            f.write('%s: %s\\n' % (key, args[key]))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_kG7RxaR4RtI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    if n_same == 0 or n_diff == 0:\n",
    "        return 0, 0\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "    return val, far\n",
    "\n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\n",
    "    assert (embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert (embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "\n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff), 1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            if np.sum(actual_issame[train_set]) == 0 or \\\n",
    "                    np.sum(np.logical_not(actual_issame[train_set])) == 0:\n",
    "                continue\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set],\n",
    "                                                            actual_issame[train_set])\n",
    "        if np.max(far_train) >= far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "        if np.sum(actual_issame[train_set]) == 0 or \\\n",
    "                np.sum(np.logical_not(actual_issame[train_set])) == 0:\n",
    "            continue\n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set],\n",
    "                                                         actual_issame[test_set])\n",
    "\n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "\n",
    "    tpr = 0 if (tp + fn == 0) else float(tp) / float(tp + fn)\n",
    "    fpr = 0 if (fp + tn == 0) else float(fp) / float(fp + tn)\n",
    "    acc = float(tp + tn) / dist.size\n",
    "    return tpr, fpr, acc\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10):\n",
    "    assert (embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert (embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    tprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "\n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff), 1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "\n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx, threshold_idx], fprs[fold_idx, threshold_idx], _ = calculate_accuracy(threshold,\n",
    "                                                                                                 dist[test_set],\n",
    "                                                                                                 actual_issame[\n",
    "                                                                                                     test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set],\n",
    "                                                      actual_issame[test_set])\n",
    "\n",
    "    tpr = np.mean(tprs, 0)\n",
    "    fpr = np.mean(fprs, 0)\n",
    "    return tpr, fpr, accuracy"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dWCZ51_D4RtQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def facenet_train(total_loss, global_step, optimizer, learning_rate,\n",
    "          moving_average_decay, update_gradient_vars, log_histograms=True):\n",
    "    # Generate moving averages of all losses and associated summaries.\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "        if optimizer == 'ADAGRAD':\n",
    "            opt = tf.train.AdagradOptimizer(learning_rate)\n",
    "        elif optimizer == 'ADADELTA':\n",
    "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n",
    "        elif optimizer == 'ADAM':\n",
    "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n",
    "        elif optimizer == 'RMSPROP':\n",
    "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n",
    "        elif optimizer == 'MOM':\n",
    "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
    "        else:\n",
    "            raise ValueError('未知的优化算法')\n",
    "\n",
    "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n",
    "\n",
    "    # Apply gradients.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    # Add histograms for trainable variables.\n",
    "    if log_histograms:\n",
    "        for var in tf.trainable_variables():\n",
    "            tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    if log_histograms:\n",
    "        for grad, var in grads:\n",
    "            if grad is not None:\n",
    "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        moving_average_decay, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    return train_op"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ky-h-4W4RtV",
    "colab_type": "text"
   },
   "source": [
    "## 评价用函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oTY5nort4RtX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def read_pairs(pairs_filename):\n",
    "    pairs = []\n",
    "    with open(pairs_filename, 'r') as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            pair = line.strip().split()\n",
    "            pairs.append(pair)\n",
    "    return np.array(pairs)\n",
    "\n",
    "def get_paths(lfw_dir, pairs, file_ext):\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = os.path.join(lfw_dir, pair[0], pair[0] + '_' + '%04d' % int(pair[1])+'.'+file_ext)\n",
    "            path1 = os.path.join(lfw_dir, pair[0], pair[0] + '_' + '%04d' % int(pair[2])+'.'+file_ext)\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = os.path.join(lfw_dir, pair[0], pair[0] + '_' + '%04d' % int(pair[1])+'.'+file_ext)\n",
    "            path1 = os.path.join(lfw_dir, pair[2], pair[2] + '_' + '%04d' % int(pair[3])+'.'+file_ext)\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0, path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs > 0:\n",
    "        print('跳过 %d' % nrof_skipped_pairs)\n",
    "    \n",
    "    return path_list, issame_list\n",
    "\n",
    "def evaluate(embeddings, actual_issame, nrof_folds=10):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy = calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), nrof_folds=nrof_folds)\n",
    "    thresholds = np.arange(0, 4, 0.001)\n",
    "    val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds)\n",
    "    return tpr, fpr, accuracy, val, val_std, far"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laXVyjhq4Rtt",
    "colab_type": "text"
   },
   "source": [
    "## 训练代码"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JvPotRHJ4Rtw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 从文件中读取学习率\n",
    "def get_learning_rate_from_file(filename, epoch):\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split('#', 1)[0]\n",
    "            if line:\n",
    "                par = line.strip().split(':')\n",
    "                e = int(par[0])\n",
    "                lr = float(par[1])\n",
    "                if e <= epoch:\n",
    "                    learning_rate = lr\n",
    "                else:\n",
    "                    return learning_rate\n",
    "\n",
    "# 从数据集中进行抽样图片，输入参数：\n",
    "# 1、训练数据集  2、每一个batch抽样多少人 3、每个人抽样多少张\n",
    "# 默认：选择40张人脸图片作为正样本，随机筛选其他人脸图片作为负样本\n",
    "def sample_people(dataset, people_per_batch, images_per_person):\n",
    "    # 总共应该抽取多少张    people_per_batch：45  images_per_person：40\n",
    "    nrof_images = people_per_batch * images_per_person\n",
    "    # 数据量不够，暂时用这个代替\n",
    "    # nrof_images = 900\n",
    "\n",
    "    # 数据集中一共有多少个不同人的图像\n",
    "    nrof_classes = len(dataset)\n",
    "\n",
    "    class_indices = np.arange(nrof_classes)\n",
    "    # 随机打乱数据\n",
    "    np.random.shuffle(class_indices)\n",
    "\n",
    "    i = 0\n",
    "    image_paths = []\n",
    "    num_per_class = []\n",
    "    sampled_class_indices = []\n",
    "    # 循环抽样，直到满足最小批\n",
    "    while len(image_paths) < nrof_images:\n",
    "        class_index = class_indices[i]\n",
    "        nrof_images_in_class = len(dataset[class_index])\n",
    "        image_indices = np.arange(nrof_images_in_class)\n",
    "        np.random.shuffle(image_indices)\n",
    "        nrof_images_from_class = min(nrof_images_in_class, images_per_person, nrof_images - len(image_paths))\n",
    "        # nrof_images_from_class = min(nrof_images_in_class, 20, nrof_images - len(image_paths))\n",
    "        idx = image_indices[0:nrof_images_from_class]\n",
    "        # 图片路径 image_paths_for_class：每一类的图片\n",
    "        image_paths_for_class = [dataset[class_index].image_paths[j] for j in idx]\n",
    "        # 图片label（即文件名）\n",
    "        sampled_class_indices += [class_index] * nrof_images_from_class\n",
    "        image_paths += image_paths_for_class\n",
    "        num_per_class.append(nrof_images_from_class)\n",
    "        i += 1\n",
    "    return image_paths, num_per_class\n",
    "\n",
    "# 选择一个用于训练的三元组\n",
    "def select_triplets(embeddings, nrof_images_per_class, image_paths, people_per_batch, alpha):\n",
    "    trip_idx = 0\n",
    "    emb_start_idx = 0\n",
    "    num_trips = 0\n",
    "    triplets = []\n",
    "    \"\"\" \n",
    "    VGG Face: Choosing good triplets is crucial and should strike a balance between\n",
    "    selecting informative (i.e. challenging) examples and swamping training with examples that\n",
    "    are too hard. This is achieve by extending each pair (a, p) to a triplet (a, p, n) by sampling\n",
    "    the image n at random, but only between the ones that violate the triplet loss margin. The\n",
    "    latter is a form of hard-negative mining, but it is not as aggressive (and much cheaper) than\n",
    "    choosing the maximally violating example, as often done in structured output learning.\n",
    "    \n",
    "    选择好的三元组是至关重要的，应该选择对于深度学习网络具有挑战的例子。\n",
    "    \"\"\"\n",
    "    # 遍历每一个人\n",
    "    for i in xrange(people_per_batch):\n",
    "        # 这个人对应了几张图片\n",
    "        nrof_images = int(nrof_images_per_class[i])\n",
    "        # 遍历第i个人的所有图片\n",
    "        for j in xrange(1, nrof_images):\n",
    "            a_idx = emb_start_idx + j - 1\n",
    "            neg_dists_sqr = np.sum(np.square(embeddings[a_idx] - embeddings), 1)\n",
    "            # For every possible positive pair.\n",
    "            for pair in xrange(j, nrof_images):\n",
    "                p_idx = emb_start_idx + pair\n",
    "                pos_dist_sqr = np.sum(np.square(embeddings[a_idx] - embeddings[p_idx]))\n",
    "                neg_dists_sqr[emb_start_idx:emb_start_idx + nrof_images] = np.NaN\n",
    "                # FaceNet\n",
    "                all_neg = np.where(np.logical_and(neg_dists_sqr-pos_dist_sqr<alpha, pos_dist_sqr<neg_dists_sqr))[0]\n",
    "                # VGG Face\n",
    "                # all_neg = np.where(neg_dists_sqr - pos_dist_sqr < alpha)[0]\n",
    "                nrof_random_negs = all_neg.shape[0]\n",
    "                if nrof_random_negs > 0:\n",
    "                    rnd_idx = np.random.randint(nrof_random_negs)\n",
    "                    n_idx = all_neg[rnd_idx]\n",
    "                    triplets.append((image_paths[a_idx], image_paths[p_idx], image_paths[n_idx]))\n",
    "                    # print('Triplet %d: (%d, %d, %d), pos_dist=%2.6f, neg_dist=%2.6f (%d, %d, %d, %d, %d)' %\n",
    "                    #    (trip_idx, a_idx, p_idx, n_idx, pos_dist_sqr, neg_dists_sqr[n_idx],\n",
    "                    #    nrof_random_negs, rnd_idx, i, j, emb_start_idx))\n",
    "                    trip_idx += 1\n",
    "\n",
    "                num_trips += 1\n",
    "\n",
    "        emb_start_idx += nrof_images\n",
    "\n",
    "    np.random.shuffle(triplets)\n",
    "    return triplets, num_trips, len(triplets)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UI5KAgrz4Rtz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 训练\n",
    "def train(args, sess, dataset, epoch, image_paths_placeholder, labels_placeholder, labels_batch,\n",
    "          batch_size_placeholder, learning_rate_placeholder, phase_train_placeholder, enqueue_op, input_queue,\n",
    "          global_step,\n",
    "          embeddings, loss, train_op, summary_op, summary_writer, learning_rate_schedule_file,\n",
    "          embedding_size, anchor, positive, negative, triplet_loss):\n",
    "    batch_number = 0\n",
    "    # 学习率大于 0\n",
    "    if args['learning_rate'] > 0.0:\n",
    "        lr = args['learning_rate']\n",
    "    else:\n",
    "        lr = facenet_get_learning_rate_from_file(learning_rate_schedule_file, epoch)\n",
    "    # 运行一个批处理\n",
    "    while batch_number < args['epoch_size']:\n",
    "        # 随机选取数据\n",
    "        # 1800 个\n",
    "        image_paths, num_per_class = sample_people(dataset,\n",
    "                                                   args['people_per_batch'],\n",
    "                                                   args['images_per_person'])\n",
    "\n",
    "        print('进行前向传播:', end='')\n",
    "        start_time = time.time()\n",
    "        examples = args['people_per_batch'] * args['images_per_person']\n",
    "        # 将输入的1800个图像变成了600*3的二维数据，\n",
    "        # reshape(a,(-1,3))表示只给定列数为3, 行数自行算出\n",
    "        labels_array = np.reshape(np.arange(examples), (-1, 3))\n",
    "        image_paths_array = np.reshape(np.expand_dims(np.array(image_paths), 1), (-1, 3))\n",
    "        # 开辟一个新的线程用于在内存里读取数据\n",
    "        sess.run(enqueue_op,\n",
    "                 {image_paths_placeholder: image_paths_array,\n",
    "                  labels_placeholder: labels_array})\n",
    "        emb_array = np.zeros((examples, embedding_size))\n",
    "        # nrof_batches，1800/90=20\n",
    "        nrof_batches = int(np.ceil(examples / args['batch_size']))\n",
    "        # 批处理取得人脸特征，默认为20个批\n",
    "        for i in range(nrof_batches):\n",
    "            batch_size = min(examples - i * args['batch_size'], args['batch_size'])\n",
    "            emb, lab = sess.run([embeddings, labels_batch],\n",
    "                                feed_dict={batch_size_placeholder: batch_size,\n",
    "                                           learning_rate_placeholder: lr,\n",
    "                                           phase_train_placeholder: True})\n",
    "            emb_array[lab, :] = emb\n",
    "        print('%.3f' % (time.time() - start_time))\n",
    "\n",
    "        print('选择合适的三元组')\n",
    "        triplets, nrof_random_negs, nrof_triplets = select_triplets(emb_array,\n",
    "                                                                    num_per_class,\n",
    "                                                                    image_paths,\n",
    "                                                                    args['people_per_batch'],\n",
    "                                                                    args['alpha'])\n",
    "        selection_time = time.time() - start_time\n",
    "        print('(random_negs, triplets) = (%d, %d): time=%.3f seconds' %\n",
    "              (nrof_random_negs, nrof_triplets, selection_time))\n",
    "\n",
    "        # 使用选定的三元组训练\n",
    "        nrof_batches = int(np.ceil(nrof_triplets * 3 / args['batch_size']))\n",
    "        triplet_paths = list(itertools.chain(*triplets))\n",
    "        labels_array = np.reshape(np.arange(len(triplet_paths)), (-1, 3))\n",
    "        triplet_paths_array = np.reshape(np.expand_dims(np.array(triplet_paths), 1), (-1, 3))\n",
    "        # 读取数据的操作\n",
    "        sess.run(enqueue_op,\n",
    "                 {image_paths_placeholder: triplet_paths_array,\n",
    "                  labels_placeholder: labels_array})\n",
    "        examples = len(triplet_paths)\n",
    "        train_time = 0\n",
    "        i = 0\n",
    "        emb_array = np.zeros((examples, embedding_size))\n",
    "        loss_array = np.zeros((nrof_triplets,))\n",
    "        # 根据求出的特征计算triplet损失函数并进行优化\n",
    "        summary = tf.Summary()\n",
    "        while i < nrof_batches:\n",
    "            start_time = time.time()\n",
    "            batch_size = min(examples - i * args['batch_size'], args['batch_size'])\n",
    "            feed_dict = {batch_size_placeholder: batch_size,\n",
    "                         learning_rate_placeholder: lr,\n",
    "                         phase_train_placeholder: True}\n",
    "            # sess run 有5个输入，fetches，先运行loss\n",
    "            # 前向计算的损失，train_op是根据损失来计算梯度，来对参数进行优化\n",
    "            err, _, step, emb, lab = sess.run([loss, train_op, global_step,\n",
    "                                               embeddings, labels_batch],\n",
    "                                              feed_dict=feed_dict)\n",
    "            emb_array[lab, :] = emb\n",
    "            loss_array[i] = err\n",
    "            duration = time.time() - start_time\n",
    "            print('Epoch: [%d][%d/%d]\\tTime %.3f\\tLoss %2.3f' %\n",
    "                  (epoch, batch_number + 1, args['epoch_size'], duration, err))\n",
    "            batch_number += 1\n",
    "            i += 1\n",
    "            train_time += duration\n",
    "            summary.value.add(tag='loss', simple_value=err)\n",
    "\n",
    "        # 将验证损失和准确性添加到summary\n",
    "        summary.value.add(tag='time/selection', simple_value=selection_time)\n",
    "        summary_writer.add_summary(summary, step)\n",
    "    return step\n",
    "\n",
    "# 保存模型\n",
    "def save_variables_and_metagraph(sess, saver, summary_writer, model_dir, model_name, step):\n",
    "    # 保存checkpoint\n",
    "    print('保存变量')\n",
    "    start_time = time.time()\n",
    "    checkpoint_path = os.path.join(model_dir, 'model-%s.ckpt' % model_name)\n",
    "    saver.save(sess, checkpoint_path, global_step=step, write_meta_graph=False)\n",
    "    save_time_variables = time.time() - start_time\n",
    "    print('变量保存完成，耗时：%.2f s' % save_time_variables)\n",
    "    metagraph_filename = os.path.join(model_dir, 'model-%s.meta' % model_name)\n",
    "    save_time_metagraph = 0\n",
    "    if not os.path.exists(metagraph_filename):\n",
    "        print('保存metagraph')\n",
    "        start_time = time.time()\n",
    "        saver.export_meta_graph(metagraph_filename)\n",
    "        save_time_metagraph = time.time() - start_time\n",
    "        print('保存完成，耗时：%.2f s' % save_time_metagraph)\n",
    "    summary = tf.Summary()\n",
    "    summary.value.add(tag='time/save_variables', simple_value=save_time_variables)\n",
    "    summary.value.add(tag='time/save_metagraph', simple_value=save_time_metagraph)\n",
    "    summary_writer.add_summary(summary, step)\n",
    "\n",
    "# 评价\n",
    "def eval(sess, image_paths, embeddings, labels_batch, image_paths_placeholder,\n",
    "             labels_placeholder,\n",
    "             batch_size_placeholder, learning_rate_placeholder,\n",
    "             phase_train_placeholder, enqueue_op, actual_issame,\n",
    "             batch_size,\n",
    "             nrof_folds, log_dir, step, summary_writer, embedding_size):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('前向传播计算特征量: ', end='')\n",
    "    nrof_images = len(actual_issame) * 2\n",
    "    assert (len(image_paths) == nrof_images)\n",
    "    labels_array = np.reshape(np.arange(nrof_images), (-1, 3))\n",
    "    image_paths_array = np.reshape(np.expand_dims(np.array(image_paths), 1), (-1, 3))\n",
    "    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array,\n",
    "                          labels_placeholder: labels_array})\n",
    "    emb_array = np.zeros((nrof_images, embedding_size))\n",
    "    nrof_batches = int(np.ceil(nrof_images / batch_size))\n",
    "    label_check_array = np.zeros((nrof_images,))\n",
    "    for i in xrange(nrof_batches):\n",
    "        batch_size = min(nrof_images - i * batch_size, batch_size)\n",
    "        emb, lab = sess.run([embeddings, labels_batch],\n",
    "                            feed_dict={batch_size_placeholder: batch_size,\n",
    "                                       learning_rate_placeholder: 0.0,\n",
    "                                       phase_train_placeholder: False})\n",
    "        emb_array[lab, :] = emb\n",
    "        label_check_array[lab] = 1\n",
    "    print('%.3f' % (time.time() - start_time))\n",
    "\n",
    "    assert (np.all(label_check_array == 1))\n",
    "\n",
    "    _, _, accuracy, val, val_std, far = evaluate(emb_array, actual_issame,\n",
    "                                                     nrof_folds=nrof_folds)\n",
    "\n",
    "    print('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "    print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "    lfw_time = time.time() - start_time\n",
    "\n",
    "    summary = tf.Summary()\n",
    "    summary.value.add(tag='lfw/accuracy', simple_value=np.mean(accuracy))\n",
    "    summary.value.add(tag='lfw/val_rate', simple_value=val)\n",
    "    summary.value.add(tag='time/lfw', simple_value=lfw_time)\n",
    "    summary_writer.add_summary(summary, step)\n",
    "    with open(os.path.join(log_dir, 'lfw_result.txt'), 'at') as f:\n",
    "        f.write('%d\\t%.5f\\t%.5f\\n' % (step, np.mean(accuracy), val))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EAaY3O6l4Rt5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def start(args):\n",
    "    # 导入网络架构模型\n",
    "    network = importlib.import_module(args['model_def'])\n",
    "    # 用当前日期来命名模型\n",
    "    subdir = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "    # 日志保存目录\n",
    "    log_dir = os.path.join(os.path.expanduser(args['logs_base_dir']), subdir)\n",
    "    # 没有日志文件就创建一个\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    model_dir = os.path.join(os.path.expanduser(args['models_base_dir']), subdir)\n",
    "    # 没有模型保存目录就创建一个\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # 保存参数日志\n",
    "    write_arguments_to_file(args, os.path.join(log_dir, 'arguments.txt'))\n",
    "\n",
    "    # 设置随机数种子\n",
    "    np.random.seed(seed=args['seed'])\n",
    "\n",
    "    # 获取数据集，train_set是包含文件路径与标签的集合\n",
    "    # 包含图片地址的（image_paths）以及对应的人名(name)\n",
    "    train_set = get_dataset(args['data_dir'])\n",
    "\n",
    "    print('模型目录: %s' % model_dir)\n",
    "    print('log目录: %s' % log_dir)\n",
    "    # 判断是否有预训练模型\n",
    "    if args['pretrained_model']:\n",
    "        print('Pre-trained model: %s' % os.path.expanduser(args['pretrained_model']))\n",
    "\n",
    "    if args['lfw_dir']:\n",
    "        print('LFW目录: %s' % args['lfw_dir'])\n",
    "        # 读取用于测试的pairs文件\n",
    "        pairs = read_pairs(os.path.expanduser(args['lfw_pairs']))\n",
    "        # 获取对应的路径\n",
    "        lfw_paths, actual_issame = get_paths(os.path.expanduser(args['lfw_dir']),\n",
    "                                                 pairs, args['lfw_file_ext'])\n",
    "\n",
    "    # 建立图\n",
    "    with tf.Graph().as_default():\n",
    "        tf.set_random_seed(args['seed'])\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        # 学习率\n",
    "        learning_rate_placeholder = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        # 批大小\n",
    "        batch_size_placeholder = tf.placeholder(tf.int32, name='batch_size')\n",
    "        # 用于判断是训练还是测试\n",
    "        phase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n",
    "        # 图像路径\n",
    "        image_paths_placeholder = tf.placeholder(tf.string, shape=(None, 3), name='image_paths')\n",
    "        # 图像标签\n",
    "        labels_placeholder = tf.placeholder(tf.int64, shape=(None, 3), name='labels')\n",
    "        # 新建一个队列，数据流操作，先入先出\n",
    "        input_queue = data_flow_ops.FIFOQueue(capacity=100000,\n",
    "                                              dtypes=[tf.string, tf.int64],\n",
    "                                              shapes=[(3,), (3,)],\n",
    "                                              shared_name=None, name=None)\n",
    "        # enqueue_many返回的是一个操作\n",
    "        enqueue_op = input_queue.enqueue_many([image_paths_placeholder, labels_placeholder])\n",
    "\n",
    "        preprocess_threads = 4\n",
    "        images_and_labels = []\n",
    "        for _ in range(preprocess_threads):\n",
    "            filenames, label = input_queue.dequeue()\n",
    "            images = []\n",
    "            for filename in tf.unstack(filenames):\n",
    "                file_contents = tf.read_file(filename)\n",
    "                image = tf.image.decode_image(file_contents, channels=3)\n",
    "                # 随机裁剪\n",
    "                if args['random_crop']:\n",
    "                    image = tf.random_crop(image, [args['image_size'], args['image_size'], 3])\n",
    "                else:\n",
    "                    image = tf.image.resize_image_with_crop_or_pad(image, args['image_size'],\n",
    "                                                                   args['image_size'])\n",
    "                # 随机水平反转\n",
    "                if args['random_flip']:\n",
    "                    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "                image.set_shape((args['image_size'], args['image_size'], 3))\n",
    "                images.append(tf.image.per_image_standardization(image))\n",
    "            images_and_labels.append([images, label])\n",
    "\n",
    "        image_batch, labels_batch = tf.train.batch_join(\n",
    "            images_and_labels, batch_size=batch_size_placeholder,\n",
    "            shapes=[(args['image_size'], args['image_size'], 3), ()], enqueue_many=True,\n",
    "            capacity=4 * preprocess_threads * args['batch_size'],\n",
    "            allow_smaller_final_batch=True)\n",
    "        image_batch = tf.identity(image_batch, 'image_batch')\n",
    "        image_batch = tf.identity(image_batch, 'input')\n",
    "        labels_batch = tf.identity(labels_batch, 'label_batch')\n",
    "\n",
    "        # 构造计算图\n",
    "        # 其中prelogits是最后一层的输出\n",
    "        prelogits, _ = network.inference(image_batch, args['keep_probability'],\n",
    "                                         phase_train=phase_train_placeholder,\n",
    "                                         bottleneck_layer_size=args['embedding_size'],\n",
    "                                         weight_decay=args['weight_decay'])\n",
    "\n",
    "        # L2正则化\n",
    "        # embeddings = tf.nn.l2_normalize\n",
    "        # 输入向量, L2范化的维数（取0（列L2范化）或1（行L2范化））\n",
    "        # 泛化的最小值边界, name='embeddings')\n",
    "        embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name='embeddings')\n",
    "\n",
    "        # 计算 triplet_loss\n",
    "        anchor, positive, negative = tf.unstack(tf.reshape(embeddings, [\n",
    "            -1, 3, args['embedding_size']]), 3, 1)\n",
    "        triplet_loss = triplet(anchor, positive, negative, args['alpha'])\n",
    "\n",
    "        # 将指数衰减应用在学习率上\n",
    "        learning_rate = tf.train.exponential_decay(learning_rate_placeholder, global_step,\n",
    "                                                   args['learning_rate_decay_epochs']\\\n",
    "                                                   * args['epoch_size'],\n",
    "                                                   args['learning_rate_decay_factor'],\n",
    "                                                   staircase=True)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "        # 计算损失\n",
    "        regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        # 构建L2正则化\n",
    "        total_loss = tf.add_n([triplet_loss] + regularization_losses, name='total_loss')\n",
    "\n",
    "        # 确定优化方法并根据损失函求梯度，每更新一次参数，global_step 会加 1\n",
    "        train_op = facenet_train(total_loss, global_step, args['optimizer'],\n",
    "                                 learning_rate, args['moving_average_decay'],\n",
    "                                 tf.global_variables())\n",
    "\n",
    "        # 创建一个saver用来保存或者从内存中读取一个模型参数\n",
    "        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        # 设置显存比例\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args['gpu_memory_fraction'])\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "        # 初始化变量\n",
    "        sess.run(tf.global_variables_initializer(), feed_dict={phase_train_placeholder: True})\n",
    "        sess.run(tf.local_variables_initializer(), feed_dict={phase_train_placeholder: True})\n",
    "\n",
    "        # 写log文件\n",
    "        summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "        # 获取线程坐标\n",
    "        coord = tf.train.Coordinator()\n",
    "        # 将队列中的多用sunner开始执行\n",
    "        tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "        with sess.as_default():\n",
    "            # 读入预训练模型（如果有）\n",
    "            if args['pretrained_model']:\n",
    "                print('载入预训练模型: %s' % args['pretrained_model'])\n",
    "                # saver.restore(sess, os.path.expanduser(args['pretrained_model']))\n",
    "                load_model(args['pretrained_model'])\n",
    "\n",
    "            epoch = 0\n",
    "            # 将所有数据过一遍的次数\n",
    "            while epoch < args['max_nrof_epochs']:\n",
    "                step = sess.run(global_step, feed_dict=None)\n",
    "                # epoch_size是一个epoch中批的个数\n",
    "                # epoch是全局的批处理个数以一个epoch中。。。这个epoch将用于求学习率\n",
    "                epoch = step // args['epoch_size']\n",
    "                # 训练一个epoch\n",
    "                train(args, sess, train_set, epoch, image_paths_placeholder,\n",
    "                      labels_placeholder, labels_batch,\n",
    "                      batch_size_placeholder, learning_rate_placeholder,\n",
    "                      phase_train_placeholder, enqueue_op,\n",
    "                      input_queue, global_step,\n",
    "                      embeddings, total_loss, train_op, summary_op,\n",
    "                      summary_writer, args['learning_rate_schedule_file'],\n",
    "                      args['embedding_size'], anchor, positive, negative, triplet_loss)\n",
    "\n",
    "                # 保存变量和metagraph（如果不存在）\n",
    "                save_variables_and_metagraph(sess, saver, summary_writer,\n",
    "                                             model_dir, subdir, step)\n",
    "\n",
    "                # 使用lfw评价当前模型\n",
    "                if args['lfw_dir']:\n",
    "                    eval(sess, lfw_paths, embeddings, labels_batch,\n",
    "                             image_paths_placeholder, labels_placeholder,\n",
    "                             batch_size_placeholder, learning_rate_placeholder,\n",
    "                             phase_train_placeholder, enqueue_op,\n",
    "                             actual_issame, args['batch_size'],\n",
    "                             args['lfw_nrof_folds'], log_dir, step, summary_writer,\n",
    "                             args['embedding_size'])\n",
    "\n",
    "    return model_dir"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F8BhWgUF4Rt7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# 训练参数\n",
    "args = {\n",
    "    # 日志目录\n",
    "    'logs_base_dir': './gdrive/My Drive/logs/facenet',\n",
    "    # 模型目录\n",
    "    'models_base_dir': './gdrive/My Drive/facenet_models',\n",
    "    # GPU显存占用比例\n",
    "    'gpu_memory_fraction': 0.98,\n",
    "    # 预训练模型目录\n",
    "    'pretrained_model': './gdrive/My Drive/facenet_models/pre_train/20200507-114759.pb',\n",
    "    # 'pretrained_model': '',\n",
    "    # 对齐后的数据路径（训练集）\n",
    "    'data_dir': './gdrive/My Drive/data',\n",
    "    # 网络模型（模块.名称）（models目录下的inception_resnet_v1.py）\n",
    "    'model_def': 'inception_resnet_v1',\n",
    "    # epoch\n",
    "    'max_nrof_epochs': 500,\n",
    "    # 批大小\n",
    "    'batch_size': 90,\n",
    "    # 输入图片大小\n",
    "    'image_size': 160,\n",
    "    # 每批的人数\n",
    "    'people_per_batch': 45,\n",
    "    # 每个人的图片数\n",
    "    'images_per_person': 20,\n",
    "    # 每个epoch的批的数量\n",
    "    'epoch_size': 1000,\n",
    "    # 正三元组到负三元组的边距\n",
    "    'alpha': 0.2,\n",
    "    # 特征向量维度\n",
    "    'embedding_size': 512,\n",
    "    # 对训练图像进行随机裁剪\n",
    "    # 如果为false，则使用训练图像的中心image_size像素\n",
    "    # 如果数据目录中图像的大小等于image_size，则不进行裁剪\n",
    "    'random_crop': True,\n",
    "    # 对训练图像执行随机水平翻转\n",
    "    'random_flip': True,\n",
    "    # 保持全连接层的丢失概率\n",
    "    'keep_probability': 0.8,\n",
    "    # L2 正则化\n",
    "    'weight_decay': 5e-4,\n",
    "    # 优化算法\n",
    "    'optimizer': 'ADAGRAD',\n",
    "    # 学习率\n",
    "    # 如果设为负值，可以在学习率计划文件中\n",
    "    # 指定每个epoch的学习率\n",
    "    'learning_rate': 0.1,\n",
    "    # 包含将learning_rate设置为负数时使用的学习率计划文件\n",
    "    'learning_rate_schedule_file': './gdrive/My Drive/data/learning_rate_schedule.txt',\n",
    "    # 学习率衰减之间的epoch数\n",
    "    'learning_rate_decay_epochs': 100,\n",
    "    # 学习率衰减因子\n",
    "    'learning_rate_decay_factor': 1.0,\n",
    "    # 跟踪训练参数的指数衰减\n",
    "    'moving_average_decay': 0.9999,\n",
    "    # 随机数种子\n",
    "    'seed': 666,\n",
    "\n",
    "    # lfw数据集的pairs文件路径\n",
    "    'lfw_pairs': './gdrive/My Drive/lfw_160/pairs.txt',\n",
    "    # lfw数据集的文件后缀（png/jpg)\n",
    "    'lfw_file_ext': 'png',\n",
    "    # 对齐后的lfw数据路径\n",
    "    'lfw_dir': './gdrive/My Drive/lfw_160',\n",
    "    # 交叉验证的文件夹数（主要用于测试）\n",
    "    'lfw_nrof_folds': 10\n",
    "}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lgU12hbI4Rt9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "outputId": "f7af5023-1fd0-4971-94dc-c49f8a2a4d3f"
   },
   "source": [
    "start(args)"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-bea489debe7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-34f2232f3739>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# 获取数据集，train_set是包含文件路径与标签的集合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# 包含图片地址的（image_paths）以及对应的人名(name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'模型目录: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-9af09b8c8a8e>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(path, has_class_directories)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mfacedir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-9af09b8c8a8e>\u001b[0m in \u001b[0;36mget_image_paths\u001b[0;34m(facedir)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 如果这个姓名下有图像，则读取图像列表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HYJiF4nh4Rt_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}